{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c898e6-8aef-474b-b453-25fe24b7d62e",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3bf9e0-02f3-4cb9-878e-3b782751043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fff77e1-d63c-45a3-886a-29b34f9a1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df03828-58e8-4383-a1ee-c100e5dc63c1",
   "metadata": {},
   "source": [
    "## READING DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7639d652-9123-447c-89ac-a393272a63af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Junction</th>\n",
       "      <th>Vehicles</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/11/15 0:00</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20151101001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/11/15 1:00</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>20151101011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/11/15 2:00</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20151101021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/11/15 3:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20151101031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/11/15 4:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20151101041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DateTime  Junction  Vehicles           ID\n",
       "0  01/11/15 0:00         1        15  20151101001\n",
       "1  01/11/15 1:00         1        13  20151101011\n",
       "2  01/11/15 2:00         1        10  20151101021\n",
       "3  01/11/15 3:00         1         7  20151101031\n",
       "4  01/11/15 4:00         1         9  20151101041"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the collected data into pandas DataFrames.\n",
    "data = pd.read_csv('Dataset_Uber Traffic.csv')\n",
    "# Check the head of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74408519-e48b-4566-962c-9778c82ad424",
   "metadata": {},
   "source": [
    "Inspect the various aspects of the Uber dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e79dbc9-af40-4e28-a242-2eb954fb50bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48120, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8a9424-bf2c-479b-90c7-d4e6b74f2392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48120 entries, 0 to 48119\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   DateTime  48120 non-null  object\n",
      " 1   Junction  48120 non-null  int64 \n",
      " 2   Vehicles  48120 non-null  int64 \n",
      " 3   ID        48120 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244a9192-77ff-46b9-aa2d-4b8765216f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Junction</th>\n",
       "      <th>Vehicles</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48120.000000</td>\n",
       "      <td>48120.000000</td>\n",
       "      <td>4.812000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.180549</td>\n",
       "      <td>22.791334</td>\n",
       "      <td>2.016330e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.966955</td>\n",
       "      <td>20.750063</td>\n",
       "      <td>5.944854e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.015110e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.016042e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.016093e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.017023e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.017063e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Junction      Vehicles            ID\n",
       "count  48120.000000  48120.000000  4.812000e+04\n",
       "mean       2.180549     22.791334  2.016330e+10\n",
       "std        0.966955     20.750063  5.944854e+06\n",
       "min        1.000000      1.000000  2.015110e+10\n",
       "25%        1.000000      9.000000  2.016042e+10\n",
       "50%        2.000000     15.000000  2.016093e+10\n",
       "75%        3.000000     29.000000  2.017023e+10\n",
       "max        4.000000    180.000000  2.017063e+10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf970d-67a9-4173-8568-0069fc10abf1",
   "metadata": {},
   "source": [
    "Let's do a sanity check on the dataframe for missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb709f-03fd-407e-b949-c280dc02dbc4",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62772b19-69f7-4dcc-a7e4-d096160251ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime    0.0\n",
       "Junction    0.0\n",
       "Vehicles    0.0\n",
       "ID          0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of missing values in each column\n",
    "round(data.isnull().sum()/len(data.index), 2)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f4cdd9f-c501-4271-820b-1ddf16308bdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Loking for duplicate values,if any\n",
    "#Checking for duplicate rows\n",
    "duplicates = data.duplicated()\n",
    "print(f'Number of duplicate rows: {duplicates.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b8206-260a-46d1-9520-d8ad0e8774ca",
   "metadata": {},
   "source": [
    "In the above dataframe there are no duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c54b7ea-707b-4768-b9da-b683cbb69d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateTime    object\n",
      "Junction     int64\n",
      "Vehicles     int64\n",
      "ID           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ensuring ift he columns have appropriate data types\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e815bf36-c091-4f90-a3a1-5a3d3b740a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type conversion\n",
    "# Converting 'DateTime' column to datetime type\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db412fd-b4f0-4920-b980-af6fb6e05512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers: 3617\n"
     ]
    }
   ],
   "source": [
    "# Handling outliers using IQR method\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = data['Vehicles'].quantile(0.25)\n",
    "Q3 = data['Vehicles'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier thresholds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out the outliers\n",
    "outliers = data[(data['Vehicles'] < lower_bound) | (data['Vehicles'] > upper_bound)]\n",
    "print(f'Number of outliers: {outliers.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60a0c934-01dd-4db7-b9ca-45164c90e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Outliers\n",
    "data_clean = data[(data['Vehicles'] >= lower_bound) & (data['Vehicles'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36bd18c4-c73a-4bad-a043-0fe37a081602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data size: 48120\n",
      "Cleaned data size: 44503\n"
     ]
    }
   ],
   "source": [
    "# Verify if outliers are removed\n",
    "print(f'Original data size: {data.shape[0]}')\n",
    "print(f'Cleaned data size: {data_clean.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1344e49a-86fa-498c-b6d3-675fb8a15988",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DateTime\"] = pd.to_datetime(data[\"DateTime\"])\n",
    "traffic_summary = (\n",
    "    data.groupby([\"Junction\", pd.Grouper(key=\"DateTime\", freq=\"H\")])[\"Vehicles\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52f64ff-82f6-452e-8af4-b418383a8b14",
   "metadata": {},
   "source": [
    "No outliers detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3a425ed-a87b-4c41-ab0e-bed246631450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date: 2015-01-11 00:00:00\n",
      "End Date: 2017-12-06 23:00:00\n",
      "[1 2 3 4]\n",
      "[20151101001 20151101011 20151101021 ... 20170630214 20170630224\n",
      " 20170630234]\n"
     ]
    }
   ],
   "source": [
    "# Checking the range of dates\n",
    "print(f'Start Date: {data[\"DateTime\"].min()}')\n",
    "print(f'End Date: {data[\"DateTime\"].max()}')\n",
    "\n",
    "# Check for consistency in 'Junction' and 'ID' columns\n",
    "print(data['Junction'].unique())\n",
    "print(data['ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38458ef2-4af8-46c4-8140-f3dd356f573b",
   "metadata": {},
   "source": [
    "Data is consistent and covers a time span from January 11, 2015, to December 6, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6664d-c7a2-4381-b24d-f1f2920e809f",
   "metadata": {},
   "source": [
    "## Aggregate traffic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c69ce8-bd77-4294-a14e-141b44b61260",
   "metadata": {},
   "source": [
    "#### - Compile traffic data into hourly intervals for each junction.\n",
    "#### - Ensure data includes relevant details such as vehicle counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276fc338-6506-49a0-a384-ed385e05a409",
   "metadata": {},
   "source": [
    "Resampling the data into hourly intervals with vehicle count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3fc59e3-1b69-49b3-aa48-9d39b037c5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Junction            DateTime  Vehicles\n",
      "0         1 2015-01-11 00:00:00        15\n",
      "1         1 2015-01-11 01:00:00        13\n",
      "2         1 2015-01-11 02:00:00        10\n",
      "3         1 2015-01-11 03:00:00         7\n",
      "4         1 2015-01-11 04:00:00         9\n"
     ]
    }
   ],
   "source": [
    "# Seting 'DateTime' as the index for resampling\n",
    "data.set_index('DateTime', inplace=True)\n",
    "\n",
    "# Resampling the data to hourly intervals and aggregate vehicle counts\n",
    "df_hourly = data.groupby('Junction').resample('H').agg({'Vehicles': 'sum'}).reset_index()\n",
    "\n",
    "# Check the first few rows of the aggregated data\n",
    "print(df_hourly.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda66f2a-1275-4644-85a7-81cda06aae32",
   "metadata": {},
   "source": [
    "Let's verify if there are any missing hours and data for a specific junction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "763a7ddd-9631-4666-af16-dc4ed3e11767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing hours: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing hours\n",
    "missing_hours = df_hourly[df_hourly['Vehicles'].isna()]\n",
    "print(f'Missing hours: {missing_hours.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f8c0faa-3fa7-49a1-a154-69c4897b983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Junction            DateTime  Vehicles\n",
      "76392         4 2017-01-01 00:00:00         3\n",
      "76393         4 2017-01-01 01:00:00         1\n",
      "76394         4 2017-01-01 02:00:00         4\n",
      "76395         4 2017-01-01 03:00:00         4\n",
      "76396         4 2017-01-01 04:00:00         2\n"
     ]
    }
   ],
   "source": [
    "# Checking the data for a specific junction\n",
    "junction_id = 4  # Change this to the junction of interest\n",
    "df_junction_hourly = df_hourly[df_hourly['Junction'] == junction_id]\n",
    "print(df_junction_hourly.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de0cf7-e89b-4754-8179-f73602d59c97",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1420e22-f2a8-4f3c-a873-bda6af202d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Vehicles  HourOfDay  Junction_1  Junction_2  Junction_3  Junction_4\n",
      "0  0.083333   0.000000         1.0         0.0         0.0         0.0\n",
      "1  0.072222   0.043478         1.0         0.0         0.0         0.0\n",
      "2  0.055556   0.086957         1.0         0.0         0.0         0.0\n",
      "3  0.038889   0.130435         1.0         0.0         0.0         0.0\n",
      "4  0.050000   0.173913         1.0         0.0         0.0         0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "#Extracting HourOfDay\n",
    "df_hourly['HourOfDay'] = df_hourly['DateTime'].dt.hour\n",
    "\n",
    "# Define features\n",
    "features = ['Vehicles', 'Junction', 'HourOfDay']\n",
    "\n",
    "# Separate numeric and categorical features\n",
    "numeric_features = ['Vehicles', 'HourOfDay']\n",
    "categorical_features = ['Junction']\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = MinMaxScaler()\n",
    "df_hourly[numeric_features] = scaler.fit_transform(df_hourly[numeric_features])\n",
    "\n",
    "# Encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_categorical = encoder.fit_transform(df_hourly[categorical_features])\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# Concatenate normalized numeric and encoded categorical features\n",
    "df_processed = pd.concat([df_hourly[numeric_features], encoded_categorical_df], axis=1)\n",
    "\n",
    "# Check the processed data\n",
    "print(df_processed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb78c894-43ba-41bb-a836-2dabd3ed81d4",
   "metadata": {},
   "source": [
    "### Data is processed for comprisons accross different timeperiods and junctions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
